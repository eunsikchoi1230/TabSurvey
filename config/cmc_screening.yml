# General parameters
dataset: CMCscreening
objective: multi-label_classification # Don't change

# Model used
problem_transformation: BinaryRelevance # BinaryRelevance, ClassifierChain, LabelPowerset, None
model_name: NaiveBayes # NaiveBayes, LogisticRegression, KNN, SVM, RandomForest, XGBoost, (CatBoost, LightGBM), DNN, TabNet

# Optuna parameters- https://optuna.org/
optimize_hyperparameters: False # Use Optuna to optimize hyperparameters
n_trials: 3
n_startup_trials: 0
direction: minimize

# GPU parameters
use_gpu: True
gpu_ids: [0, 1]
data_parallel: True

# Cross validation parameters 
num_splits: 3
shuffle: True
seed: 221 # Don't change 

# Test train valid split parameters
test_size: 0.2
# valid_size: 0.2 # Not needed since we are using cross validation
## Need to implement random, labelset, iterative (not implemented yet) stratification methods

# Preprocessing parameters
fill_na: True
scale: True
target_encode: False 
one_hot_encode: False

# Training parameters
batch_size: 1024
val_batch_size: 1024
early_stopping_rounds: 20
epochs: 1000
logging_period: 100

# About the data
num_classes: 4  # Number of labels
num_features: 41
cat_idx: [0, 13, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38] # Index of categorical features after dropping unused features
## cat_dims: will be automatically set.
# cat_dims: [] # Number of categories in each categorical feature